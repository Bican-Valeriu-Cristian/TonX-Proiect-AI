{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb2e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment140 loaded. Rows: 1600000\n",
      "\n",
      "First 5 rows for inspection:\n",
      "    label                                           raw_text\n",
      "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1      0  is upset that he can't update his Facebook by ...\n",
      "2      0  @Kenichan I dived many times for the ball. Man...\n",
      "3      0    my whole body feels itchy and like its on fire \n",
      "4      0  @nationwideclass no, it's not behaving at all....\n",
      "\n",
      "Twitter-sentiment-neutral loaded. Rows: 31308\n",
      "\n",
      "First 5 rows for inspection:\n",
      "     label                                           raw_text\n",
      "12      1  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "13      1  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "14      1  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "15      1  Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
      "16      1  Live Rock - Hard music La la Varlope, RARE & t...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "\n",
    "FILE_PATH = \"dataset/sentiment140/training.1600000.processed.noemoticon.csv\"\n",
    "column_names= ['label', 'id', 'date', 'query', 'user', 'raw_text']\n",
    "\n",
    "neutral_column_names = ['id', 'entity', 'sentiment', 'raw_text']\n",
    "NEUTRAL_FILE_PATH = \"dataset/twitter-sentiment-neutral/twitter_training.csv\"\n",
    "\n",
    "\n",
    "# Load the Sentiment140 dataset - df = dataframe\n",
    "df = pd.read_csv(\n",
    "  FILE_PATH, \n",
    "  encoding='ISO-8859-1', #bc sentiment130 is an old dataset with special characters\n",
    "  header=None, #doesn't have a header\n",
    "  names=column_names #because the header doesn't exist\n",
    ")\n",
    "\n",
    "df_neutral_raw = pd.read_csv(\n",
    "    NEUTRAL_FILE_PATH,\n",
    "    encoding='utf-8',  \n",
    "    header=None,\n",
    "    names=neutral_column_names\n",
    ")\n",
    "\n",
    "#filter only rows that contain neutral or irrelevant\n",
    "df_neutral = df_neutral_raw[\n",
    "    (df_neutral_raw['sentiment'] == 'Neutral') | \n",
    "    (df_neutral_raw['sentiment'] == 'Irrelevant')\n",
    "].copy()\n",
    "\n",
    "# Select only necessary columns\n",
    "df = df[['label', 'raw_text']].copy()\n",
    "df_neutral = df_neutral[['sentiment', 'raw_text']].copy()\n",
    "\n",
    "#renaming columns for consistency\n",
    "df_neutral.rename(columns={'sentiment': 'label'}, inplace=True)\n",
    "df_neutral['label'] = 1\n",
    "\n",
    "print(f\"\\nSentiment140 loaded. Rows: {len(df)}\")\n",
    "print(\"\\nFirst 5 rows for inspection:\\n\", df.head())\n",
    "\n",
    "print(f\"\\nTwitter-sentiment-neutral loaded. Rows: {len(df_neutral)}\")\n",
    "print(\"\\nFirst 5 rows for inspection:\\n\", df_neutral.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520ea1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentiment140_text(text):\n",
    "  if not isinstance(text, str):\n",
    "    return \"\"\n",
    "  \n",
    "  #lowercasting\n",
    "  text = html.unescape(text.lower())\n",
    "\n",
    "  #removes mentions '@'\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', ' ', text)\n",
    "\n",
    "  #removes url patterns\n",
    "  url_pattern = r'https?://\\S+|www\\.\\S+|\\S+\\.com\\S*'\n",
    "  text = re.sub(url_pattern, '', text)\n",
    "\n",
    "  #removes spaces\n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c205c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_twitter_sentiment_text(text):\n",
    "  if not isinstance(text, str):\n",
    "      return \"\" \n",
    "  \n",
    "  # Lowercasing & decoding HTML\n",
    "  text = html.unescape(text.lower())\n",
    "\n",
    "  # removes unknown and !! => noise\n",
    "  text = text.replace('<unk>', ' ').replace('‼', ' ')\n",
    "  \n",
    "  text = text.replace('\"', '').replace('“', '').replace('”', '')\n",
    "  \n",
    "  #removes mentions '@'\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', ' ', text)\n",
    "  \n",
    "  url_pattern = r'https?://\\S+|www\\.\\S+|[a-zA-Z0-9]+\\.[a-z]+\\S*'\n",
    "  text = re.sub(url_pattern, ' ', text)\n",
    "  \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb4e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup function for sentiment140 and twitter neutral messages\n",
      "Subsampling at 500000 rows...\n",
      "\n",
      "Final verification after cleanup and subsampling:\n",
      "Label distribution: \n",
      " label\n",
      "0    249375\n",
      "1     31308\n",
      "2    250625\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example of final clean text (Combined Dataset):\n",
      "        label                                         clean_text\n",
      "29380       2  morning everyone, or afternoon or good evening...\n",
      "195844      2  @ hey, i see interesting musical tastes. thank...\n",
      "253761      0  really wish i didn't get 8.30am phone calls ev...\n",
      "209650      0  oops haha. delayed i am. i think mine cant hol...\n",
      "475480      2                                        you're sexy\n",
      "132117      2                                          cool pics\n",
      "393225      0  is impressed by night at the museum 2 (: but i...\n",
      "390997      2                    woody says i have a magic smile\n",
      "120192      2         i am also good thank you up to much today?\n",
      "303052      0             yeah i nearly broke my ankle yesterday\n"
     ]
    }
   ],
   "source": [
    "print('Cleanup function for sentiment140 and twitter neutral messages')\n",
    "df['clean_text'] = df['raw_text'].apply(clean_sentiment140_text)\n",
    "df_neutral['clean_text'] = df_neutral['raw_text'].apply(clean_twitter_sentiment_text)\n",
    "\n",
    "#changes 4 to 2 dor Positives\n",
    "df['label'] = df['label'].replace(4, 2)\n",
    "\n",
    "#reduction of the dataset to 500K for fast prelimination training\n",
    "N_SUBSAMPLE = 500_000\n",
    "if len(df) > N_SUBSAMPLE:\n",
    "  print(f\"Subsampling at {N_SUBSAMPLE} rows...\")\n",
    "  df = df.sample(n=N_SUBSAMPLE, random_state=42)\n",
    "\n",
    "\n",
    "#keeping only necessary columns\n",
    "df_final = df[['label', 'clean_text']].copy()\n",
    "df_neutral_final = df_neutral[['label', 'clean_text']].copy()\n",
    "\n",
    "#concatenating sentiment140 with twitter messages\n",
    "df_final = pd.concat([df_final, df_neutral_final], ignore_index=True)\n",
    "\n",
    "#Final verification\n",
    "print(\"\\nFinal verification after cleanup and subsampling:\")\n",
    "print(\"Label distribution: \\n\", df_final['label'].value_counts().sort_index()) # Sortam pentru 0, 1, 2\n",
    "print(\"\\nExample of final clean text (Combined Dataset):\")\n",
    "print(df_final.sample(10, random_state=42))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
